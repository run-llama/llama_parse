{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e8f1c8-44e8-461d-9a12-13e714448fa1",
   "metadata": {},
   "source": [
    "# RFP Response Generation Workflow\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_cloud_services/blob/main/examples/parse/report_generation/rfp_response/generate_rfp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook shows you how to build a workflow to generate a response to an RFP. \n",
    "\n",
    "In this scenario, we assume that you are Microsoft, and you are responding to the [JEDI Cloud RFP](https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf) put out by the federal government. The government is using the submitted responses to decide the best vendor for their needs.\n",
    "\n",
    "![generate_rfp_img](generate_rfp_img.png)\n",
    "\n",
    "We index a set of relevant documents that Microsoft has - including its annual report, wikipedia page on Microsoft Azure, a slide deck on the government cloud and cybersecurity capabilities. We then help you build an agentic workflow that can ingest an RFP, and generate a response for it in \n",
    "a way that adheres to its guidelines.\n",
    "\n",
    "We use LlamaParse to parse the context documents as well as the RFP document itself.\n",
    "\n",
    "**NOTE**: If you want to skip the indexing complexity and use LlamaCloud instead, check out the [RFP Example using LlamaCloud](https://github.com/run-llama/llama_cloud_services-demo/blob/main/examples/report_generation/rfp_response/generate_rfp.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f28c6a-cb5e-4c16-bdc7-a69817fc4c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7137b3-5b37-4e52-bc46-b994693d2664",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We download the [JEDI RFP template](https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf).\n",
    "\n",
    "We also download the context documents for Microsoft:\n",
    "1. Microsoft 2024 10-K \n",
    "2. Azure Wikipedia page\n",
    "3. A slide deck on Microsoft Azure Government\n",
    "4. Microsoft Digital Defense Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1310efa-1422-4214-b0bf-41b6e163fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download JEDI Cloud RFP Template\n",
    "!wget \"https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf\" -O data/jedi_cloud_rfp.pdf\n",
    "# microsoft annual report\n",
    "!wget \"https://www.dropbox.com/scl/fi/4v5dx8dc9yqc8k0yw5g4h/msft_10k_2024.pdf?rlkey=jdyfrsoyb18ztlq5msunmibns&st=9w6bdyvn&dl=1\" -O data/msft_10k_2024.pdf\n",
    "# !wget \"https://microsoft.gcs-web.com/static-files/1c864583-06f7-40cc-a94d-d11400c83cc8\" -O data/msft_10k_2024.pdf\n",
    "\n",
    "# azure wikipedia page\n",
    "!wget \"https://www.dropbox.com/scl/fi/7waur8ravmve3fe8nej0k/azure_wiki.pdf?rlkey=icru2w64oylx1p76ftt6y9irv&st=fr87vxob&dl=1\" -O data/azure_wiki.pdf\n",
    "# azure government slide deck\n",
    "!wget \"https://cdn.ymaws.com/flclerks.site-ym.com/resource/resmgr/2017_Fall_Conf/Presentations/2018-10-12_FCCC_Microsoft_Az.pdf\" -O data/azure_gov.pdf\n",
    "# microsoft cybersecurity capabilities\n",
    "!wget \"https://www.dropbox.com/scl/fi/qh00xz29rlom4md8ce675/microsoft_ddr.pdf?rlkey=d868nbnsu1ng41y1chw69y64b&st=24iqemb1&dl=1\" -O data/msft_ddr.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28f1ce-9618-47a2-9fc9-0502a382d841",
   "metadata": {},
   "source": [
    "We then parse the context documents with LlamaParse - we use multimodal mode in order to extract text from visual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cddd64-b886-4b0a-b010-2c0168b42147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cloud_services import LlamaParse\n",
    "\n",
    "# use our multimodal models for extractions\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"anthropic-sonnet-3.5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85d79c-8835-4684-9883-f6342ceb44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = \"data\"\n",
    "data_out_dir = \"data_out_rfp\"\n",
    "\n",
    "!mkdir -p {data_dir}\n",
    "!mkdir -p {data_out_dir}\n",
    "\n",
    "# note: we skip the rfp doc, which will be indexed as part of the workflow\n",
    "files = [\"azure_gov.pdf\", \"azure_wiki.pdf\", \"msft_10k_2024.pdf\", \"msft_ddr.pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24920ca-878e-4aae-89e2-8fe36b0fb06f",
   "metadata": {},
   "source": [
    "**Option 1**: If you haven't parsed the files yet, run the block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58cc182-663a-4b30-9a70-5af22acbe83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_dicts = {}\n",
    "\n",
    "for f in files:\n",
    "    file_base = Path(f).stem\n",
    "    full_file_path = str(Path(data_dir) / f)\n",
    "\n",
    "    file_docs = parser.load_data(full_file_path)\n",
    "\n",
    "    # attach metadata\n",
    "    for idx, d in enumerate(file_docs):\n",
    "        d.metadata[\"file_path\"] = f\n",
    "        d.metadata[\"page_num\"] = idx + 1\n",
    "\n",
    "    file_dicts[f] = {\"file_path\": full_file_path, \"docs\": file_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7e8ed-8c2a-4434-a7f9-e695dabc6158",
   "metadata": {},
   "source": [
    "#### Generate Summaries for each file \n",
    "\n",
    "Now that we've loaded the chunks for each file, let's now generate a summary for each file. These summaries will then be attached to the tool descriptions to help inform the agent on which files to query to fetch the right information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f8dda-4e55-4917-b277-63645b3b4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "summary_llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "for f in files:\n",
    "    print(f\">> Generate summary for file {f}\")\n",
    "    index = SummaryIndex(file_dicts[f][\"docs\"])\n",
    "    response = index.as_query_engine(llm=summary_llm).query(\n",
    "        \"Generate a short 1-2 line summary of this file to help inform an agent on what this file is about.\"\n",
    "    )\n",
    "    print(f\">> Generated summary: {str(response)}\")\n",
    "    file_dicts[f][\"summary\"] = str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fd045-f1a4-47c2-a773-718608d4c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(file_dicts, open(f\"{data_out_dir}/tmp_file_dicts.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93decb8b-acb6-42fb-b7ef-2a2b0d264da3",
   "metadata": {},
   "source": [
    "**Option 2**: If you've already run parsing, the files should be cached. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6849b-4572-4315-b7d5-77ad3b7ec351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_dicts = pickle.load(open(f\"{data_out_dir}/tmp_file_dicts.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5000db-d5ca-4522-8dfa-bc64567b1884",
   "metadata": {},
   "source": [
    "### Build Indexes\n",
    "\n",
    "Once the text nodes are ready, we feed into our vector store, which will index these nodes into Chroma (you're welcome to use our other 40+ vector store integrations if you'd like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31409f-815d-4569-8b74-60fcec5af211",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101920ab-4054-4164-9f29-c3c9025c13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you want to recreate the index\n",
    "!rm -rf storage_rfp_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a2cb3-d21b-4ccf-81a0-1a83d0514a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "persist_dir = \"storage_rfp_chroma\"\n",
    "\n",
    "vector_store = ChromaVectorStore.from_params(\n",
    "    collection_name=\"rfp_docs\", persist_dir=persist_dir\n",
    ")\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f44aa-8dfa-4267-9489-d876ce056931",
   "metadata": {},
   "source": [
    "**NOTE**: Don't run the block below if you've already inserted the nodes. Only run if it's your first time!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcbaf7-9552-4ddb-9d7f-c499126c8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = [c for d in file_dicts.values() for c in d[\"docs\"]]\n",
    "index.insert_nodes(all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c4446-c477-4261-9747-c5294b0a54e9",
   "metadata": {},
   "source": [
    "### Define Retrievers\n",
    "\n",
    "Define retrievers, one for each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbac9ab-e3e2-448f-9e74-ad995415fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from typing import List\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# function tools\n",
    "def generate_tool(file: str, file_description: Optional[str] = None):\n",
    "    \"\"\"Return a function that retrieves only within a given file.\"\"\"\n",
    "    filters = MetadataFilters(\n",
    "        filters=[\n",
    "            MetadataFilter(key=\"file_path\", operator=FilterOperator.EQ, value=file),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def chunk_retriever_fn(query: str) -> str:\n",
    "        retriever = index.as_retriever(similarity_top_k=5, filters=filters)\n",
    "        nodes = retriever.retrieve(query)\n",
    "\n",
    "        full_text = \"\\n\\n========================\\n\\n\".join(\n",
    "            [n.get_content(metadata_mode=\"all\") for n in nodes]\n",
    "        )\n",
    "\n",
    "        return full_text\n",
    "\n",
    "    # define name as a function of the file\n",
    "    fn_name = Path(file).stem + \"_retrieve\"\n",
    "\n",
    "    tool_description = f\"Retrieves a small set of relevant document chunks from {file}.\"\n",
    "    if file_description is not None:\n",
    "        tool_description += f\"\\n\\nFile Description: {file_description}\"\n",
    "\n",
    "    tool = FunctionTool.from_defaults(\n",
    "        fn=chunk_retriever_fn, name=fn_name, description=tool_description\n",
    "    )\n",
    "\n",
    "    return tool\n",
    "\n",
    "\n",
    "# generate tools\n",
    "tools = []\n",
    "for f in files:\n",
    "    tools.append(generate_tool(f, file_description=file_dicts[f][\"summary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9106c7d-8c43-4443-a192-94d5f3a54ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Retrieves a small set of relevant document chunks from azure_gov.pdf.\\n\\nFile Description: This file provides an overview of Microsoft Azure Government, highlighting its secure and compliant cloud services tailored for U.S. government entities, along with features related to digital transformation, application innovation, and data-driven intelligence. It also outlines compliance standards, service models, and the commitment to security and privacy.', name='azure_gov_retrieve', fn_schema=<class 'llama_index.core.tools.utils.azure_gov_retrieve'>, return_direct=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate an existing function\n",
    "tools[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ebbad-3200-4818-aa48-705eda21503e",
   "metadata": {},
   "source": [
    "## Build Workflow\n",
    "\n",
    "Let's build a workflow that can iterate through the extracted keys/questions from the RFP, and fill them out! \n",
    "\n",
    "The user specifies an RFP document as input. The workflow then goes through the following steps:\n",
    "1. We parse the RFP template using LlamaParse\n",
    "2. We then extract out the relevant questions we'd want to ask the knowledge base given the instructions in the RFP\n",
    "3. For each question, we query the knowledge base using a specialized agent to generate a response. The agent is equipped with a set of retrieval tools over the data.\n",
    "4. We concatenate the questions/answers into a list of dictionaries.\n",
    "5. Given the question/answer pairs, we feed it along with the source RFP template into a prompt to generate the final report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740535e8-714b-4744-a515-5007834eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "from llama_index.core.llms import LLM\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "\n",
    "_logger = logging.getLogger(__name__)\n",
    "_logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# this is the research agent's system prompt, tasked with answering a specific question\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a research agent tasked with filling out a specific form key/question with the appropriate value, given a bank of context.\n",
    "You are given a specific form key/question. Think step-by-step and use the existing set of tools to help answer the question.\n",
    "\n",
    "You MUST always use at least one tool to answer each question. Only after you've determined that existing tools do not \\\n",
    "answer the question should you try to reason from first principles and prior knowledge to answer the question.\n",
    "\n",
    "You MUST try to answer the question instead of only saying 'I dont know'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is the prompt tasked with extracting information from an RFP file.\n",
    "EXTRACT_KEYS_PROMPT = \"\"\"\\\n",
    "You are provided an entire RFP document, or a large subsection from it. \n",
    "\n",
    "We wish to generate a response to the RFP in a way that adheres to the instructions within the RFP, \\\n",
    "including the specific sections that an RFP response should contain, and the content that would need to go \\\n",
    "into each section.\n",
    "\n",
    "Your task is to extract out a list of \"questions\", where each question corresponds to a specific section that is required in the RFP response.\n",
    "Put another way, after we extract out the questions we will go through each question and answer each one \\\n",
    "with our downstream research assistant, and the combined\n",
    "question:answer pairs will constitute the full RFP response.\n",
    "\n",
    "You must TRY to extract out questions that can be answered by the provided knowledge base. We provide the list of file metadata below. \n",
    "\n",
    "Additional requirements:\n",
    "- Try to make the questions SPECIFIC given your knowledge of the RFP and the knowledge base. Instead of asking a question like \\\n",
    "\"How do we ensure security\" ask a question that actually addresses a security requirement in the RFP and can be addressed by the knowledge base.\n",
    "- Make sure the questions are comprehensive and addresses all the RFP requirements.\n",
    "- Make sure each question is descriptive - this gives our downstream assistant context to fill out the value for that question \n",
    "- Extract out all the questions as a list of strings.\n",
    "\n",
    "\n",
    "Knowledge Base Files:\n",
    "{file_metadata}\n",
    "\n",
    "RFP Full Template:\n",
    "{rfp_text}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# this is the prompt that generates the final RFP response given the original template text and question-answer pairs.\n",
    "GENERATE_OUTPUT_PROMPT = \"\"\"\\\n",
    "You are an expert analyst.\n",
    "Your task is to generate an RFP response according to the given RFP and question/answer pairs.\n",
    "\n",
    "You are given the following RFP and qa pairs:\n",
    "\n",
    "<rfp_document>\n",
    "{output_template}\n",
    "</rfp_document>\n",
    "\n",
    "<question_answer_pairs>\n",
    "{answers}\n",
    "</question_answer_pairs>\n",
    "\n",
    "Not every question has an appropriate answer. This is because the agent tasked with answering the question did not have the right context to answer it.\n",
    "If this is the case, you MUST come up with an answer that is reasonable. You CANNOT say that you are unsure in any area of the RFP response.\n",
    "\n",
    "\n",
    "Please generate the output according to the template and the answers, in markdown format.\n",
    "Directly output the generated markdown content, do not add any additional text, such as \"```markdown\" or \"Here is the output:\".\n",
    "Follow the original format of the template as closely as possible, and fill in the answers into the appropriate sections.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class OutputQuestions(BaseModel):\n",
    "    \"\"\"List of keys that make up the sections of the RFP response.\"\"\"\n",
    "\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class OutputTemplateEvent(Event):\n",
    "    docs: List[Document]\n",
    "\n",
    "\n",
    "class QuestionsExtractedEvent(Event):\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class HandleQuestionEvent(Event):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class QuestionAnsweredEvent(Event):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class CollectedAnswersEvent(Event):\n",
    "    combined_answers: str\n",
    "\n",
    "\n",
    "class LogEvent(Event):\n",
    "    msg: str\n",
    "    delta: bool = False\n",
    "\n",
    "\n",
    "class RFPWorkflow(Workflow):\n",
    "    \"\"\"RFP workflow.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tools,\n",
    "        parser: LlamaParse,\n",
    "        llm: LLM | None = None,\n",
    "        similarity_top_k: int = 20,\n",
    "        output_dir: str = data_out_dir,\n",
    "        agent_system_prompt: str = AGENT_SYSTEM_PROMPT,\n",
    "        generate_output_prompt: str = GENERATE_OUTPUT_PROMPT,\n",
    "        extract_keys_prompt: str = EXTRACT_KEYS_PROMPT,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.tools = tools\n",
    "\n",
    "        self.parser = parser\n",
    "\n",
    "        self.llm = llm or OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        self.agent_system_prompt = agent_system_prompt\n",
    "        self.extract_keys_prompt = extract_keys_prompt\n",
    "\n",
    "        # if not exists, create\n",
    "        out_path = Path(self.output_dir) / \"workflow_output\"\n",
    "        if not out_path.exists():\n",
    "            out_path.mkdir(parents=True, exist_ok=True)\n",
    "            os.chmod(str(out_path), 0o0777)\n",
    "\n",
    "        self.generate_output_prompt = PromptTemplate(generate_output_prompt)\n",
    "\n",
    "    @step\n",
    "    async def parse_output_template(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> OutputTemplateEvent:\n",
    "        # load output template file\n",
    "        out_template_path = Path(\n",
    "            f\"{self.output_dir}/workflow_output/output_template.jsonl\"\n",
    "        )\n",
    "        if out_template_path.exists():\n",
    "            with open(out_template_path, \"r\") as f:\n",
    "                docs = [Document.model_validate_json(line) for line in f]\n",
    "        else:\n",
    "            docs = await self.parser.aload_data(ev.rfp_template_path)\n",
    "            # save output template to file\n",
    "            with open(out_template_path, \"w\") as f:\n",
    "                for doc in docs:\n",
    "                    f.write(doc.model_dump_json())\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "        await ctx.set(\"output_template\", docs)\n",
    "        return OutputTemplateEvent(docs=docs)\n",
    "\n",
    "    @step\n",
    "    async def extract_questions(\n",
    "        self, ctx: Context, ev: OutputTemplateEvent\n",
    "    ) -> HandleQuestionEvent:\n",
    "        docs = ev.docs\n",
    "\n",
    "        # save all_questions to file\n",
    "        out_keys_path = Path(f\"{self.output_dir}/workflow_output/all_keys.txt\")\n",
    "        if out_keys_path.exists():\n",
    "            with open(out_keys_path, \"r\") as f:\n",
    "                output_qs = [q.strip() for q in f.readlines()]\n",
    "        else:\n",
    "            # try stuffing all text into the prompt\n",
    "            all_text = \"\\n\\n\".join([d.get_content(metadata_mode=\"all\") for d in docs])\n",
    "            prompt = PromptTemplate(template=self.extract_keys_prompt)\n",
    "\n",
    "            file_metadata = \"\\n\\n\".join(\n",
    "                [\n",
    "                    f\"Name:{t.metadata.name}\\nDescription:{t.metadata.description}\"\n",
    "                    for t in tools\n",
    "                ]\n",
    "            )\n",
    "            try:\n",
    "                if self._verbose:\n",
    "                    ctx.write_event_to_stream(\n",
    "                        LogEvent(msg=\">> Extracting questions from LLM\")\n",
    "                    )\n",
    "\n",
    "                output_qs = self.llm.structured_predict(\n",
    "                    OutputQuestions,\n",
    "                    prompt,\n",
    "                    file_metadata=file_metadata,\n",
    "                    rfp_text=all_text,\n",
    "                ).questions\n",
    "\n",
    "                if self._verbose:\n",
    "                    qs_text = \"\\n\".join([f\"* {q}\" for q in output_qs])\n",
    "                    ctx.write_event_to_stream(LogEvent(msg=f\">> Questions:\\n{qs_text}\"))\n",
    "\n",
    "            except Exception as e:\n",
    "                _logger.error(f\"Error extracting questions from page: {all_text}\")\n",
    "                _logger.error(e)\n",
    "\n",
    "            with open(out_keys_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(output_qs))\n",
    "\n",
    "        await ctx.set(\"num_to_collect\", len(output_qs))\n",
    "\n",
    "        for question in output_qs:\n",
    "            ctx.send_event(HandleQuestionEvent(question=question))\n",
    "\n",
    "        return None\n",
    "\n",
    "    @step\n",
    "    async def handle_question(\n",
    "        self, ctx: Context, ev: HandleQuestionEvent\n",
    "    ) -> QuestionAnsweredEvent:\n",
    "        question = ev.question\n",
    "\n",
    "        # initialize a Function Calling \"research\" agent where given a task, it can pull responses from relevant tools and synthesize over it\n",
    "        research_agent = FunctionCallingAgentWorker.from_tools(\n",
    "            tools, llm=llm, verbose=False, system_prompt=self.agent_system_prompt\n",
    "        ).as_agent()\n",
    "\n",
    "        # ensure the agent's memory is cleared\n",
    "        response = await research_agent.aquery(question)\n",
    "\n",
    "        if self._verbose:\n",
    "            # instead of printing the message directly, write the event to stream!\n",
    "            msg = f\">> Asked question: {question}\\n>> Got response: {str(response)}\"\n",
    "            ctx.write_event_to_stream(LogEvent(msg=msg))\n",
    "\n",
    "        return QuestionAnsweredEvent(question=question, answer=str(response))\n",
    "\n",
    "    @step\n",
    "    async def combine_answers(\n",
    "        self, ctx: Context, ev: QuestionAnsweredEvent\n",
    "    ) -> CollectedAnswersEvent:\n",
    "        num_to_collect = await ctx.get(\"num_to_collect\")\n",
    "        results = ctx.collect_events(ev, [QuestionAnsweredEvent] * num_to_collect)\n",
    "        if results is None:\n",
    "            return None\n",
    "\n",
    "        combined_answers = \"\\n\".join([result.model_dump_json() for result in results])\n",
    "        # save combined_answers to file\n",
    "        with open(\n",
    "            f\"{self.output_dir}/workflow_output/combined_answers.jsonl\", \"w\"\n",
    "        ) as f:\n",
    "            f.write(combined_answers)\n",
    "\n",
    "        return CollectedAnswersEvent(combined_answers=combined_answers)\n",
    "\n",
    "    @step\n",
    "    async def generate_output(\n",
    "        self, ctx: Context, ev: CollectedAnswersEvent\n",
    "    ) -> StopEvent:\n",
    "        output_template = await ctx.get(\"output_template\")\n",
    "        output_template = \"\\n\".join(\n",
    "            [doc.get_content(\"none\") for doc in output_template]\n",
    "        )\n",
    "\n",
    "        if self._verbose:\n",
    "            ctx.write_event_to_stream(LogEvent(msg=\">> GENERATING FINAL OUTPUT\"))\n",
    "\n",
    "        resp = await self.llm.astream(\n",
    "            self.generate_output_prompt,\n",
    "            output_template=output_template,\n",
    "            answers=ev.combined_answers,\n",
    "        )\n",
    "\n",
    "        final_output = \"\"\n",
    "        async for r in resp:\n",
    "            ctx.write_event_to_stream(LogEvent(msg=r, delta=True))\n",
    "            final_output += r\n",
    "\n",
    "        # save final_output to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/final_output.md\", \"w\") as f:\n",
    "            f.write(final_output)\n",
    "\n",
    "        return StopEvent(result=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895c3b1-6ea1-41c3-bcf9-e42c2a4beb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "workflow = RFPWorkflow(\n",
    "    tools,\n",
    "    parser=parser,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    timeout=None,  # don't worry about timeout to make sure it completes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb19c4-9133-4a3f-b0bd-adf14399e21b",
   "metadata": {},
   "source": [
    "#### Visualize the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35ed08-edc1-4bd3-b80d-6e745367128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfp_workflow.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(RFPWorkflow, filename=\"rfp_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2effc-350a-46e6-b325-45c1b24b6e89",
   "metadata": {},
   "source": [
    "## Run the Workflow\n",
    "\n",
    "Let's run the full workflow and generate the output! \n",
    "\n",
    "This will take 5-20 minutes to run and complete. You can inspect the intermediate verbose outputs below as the intermediate questions/answers are generated. The response is streamed back to the user at the end - the response itself is quite long so will take a while to complete! You can also integrate with an observability provider like LlamaTrace/Arize Phoenix in order to view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7db55-aff9-4d20-aa13-4e0931b39f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step parse_output_template\n",
      "Started parsing the file under job_id ad74a9de-c9d2-44b8-ad09-8a7d8baf383f\n",
      "Step parse_output_template produced event OutputTemplateEvent\n",
      "Running step extract_questions\n",
      "Step extract_questions produced no event\n",
      "Running step handle_question\n",
      ">> Extracting questions from LLM\n",
      ">> Questions:\n",
      "* What are the specific security requirements for the JEDI Cloud as outlined in the RFP, and how can they be addressed using Microsoft Azure Government's compliance standards and security features?\n",
      "* How does the RFP define the requirements for high availability and failover in cloud services, and what solutions does Microsoft Azure offer to meet these requirements?\n",
      "* What are the RFP's stipulations regarding data portability and interoperability, and how can Microsoft Azure's services facilitate these processes?\n",
      "* What are the expectations for program management and oversight as per the RFP, and how can Microsoft Azure's management tools and practices align with these expectations?\n",
      "* How does the RFP address the need for logical isolation and secure data transfer, and what capabilities does Microsoft Azure provide to ensure these requirements are met?\n",
      "* What are the RFP's requirements for tactical edge capabilities, and how can Microsoft Azure's solutions support operations in communication-degraded or disconnected environments?\n",
      "* What does the RFP specify about the integration of third-party services and applications, and how can Microsoft Azure's marketplace and APIs support this integration?\n",
      "* How does the RFP outline the approach to small business participation, and what strategies can be employed to maximize small business involvement using Microsoft Azure's ecosystem?\n",
      "* What are the RFP's criteria for evaluating cloud service automation, and how can Microsoft Azure's automation tools and APIs fulfill these criteria?\n",
      "* What are the RFP's requirements for compliance with federal regulations and standards, and how does Microsoft Azure ensure adherence to these regulations?\n",
      "Running step handle_question\n",
      "Running step handle_question\n",
      "Running step handle_question\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: How does the RFP define the requirements for high availability and failover in cloud services, and what solutions does Microsoft Azure offer to meet these requirements?\n",
      ">> Got response: The RFP (Request for Proposal) does not explicitly define the requirements for high availability and failover in the provided context from the Azure Government document. However, Microsoft Azure offers several solutions to meet high availability and failover requirements:\n",
      "\n",
      "1. **Azure Site Recovery**: This service provides a comprehensive disaster recovery solution, allowing for site-to-Azure, any cloud, and site-to-site recovery options. It supports various operating systems, including Windows and Linux, and facilitates migration from AWS, VMware, Hyper-V, and physical servers to Azure Cloud.\n",
      "\n",
      "2. **Azure Kubernetes Service (AKS)**: AKS enables the deployment of production-ready Kubernetes clusters in Azure, which can be used to ensure high availability and manage failover scenarios.\n",
      "\n",
      "3. **Azure Functions**: These are used in serverless computing architectures, allowing for event-driven execution without managing server resources, which can contribute to high availability by automatically scaling based on demand.\n",
      "\n",
      "4. **Azure Stack HCI**: This hyper-converged infrastructure product allows for running virtualized workloads on-premises while connecting to Azure for cloud services, providing a hybrid solution for high availability.\n",
      "\n",
      "5. **Azure Fabric Controller**: This component maintains the scalability and dependability of services and environments in the data center, preventing failures and managing web applications, memory allocation, and load balancing.\n",
      "\n",
      "These solutions collectively help ensure that Microsoft Azure can meet high availability and failover requirements for cloud services.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the specific security requirements for the JEDI Cloud as outlined in the RFP, and how can they be addressed using Microsoft Azure Government's compliance standards and security features?\n",
      ">> Got response: The JEDI Cloud security requirements as outlined in the RFP are not directly available in the retrieved documents. However, Microsoft Azure Government provides a robust set of compliance standards and security features that can address typical security requirements for government cloud services, which may align with JEDI Cloud's needs. Here are some key points:\n",
      "\n",
      "1. **Compliance Standards**: Microsoft Azure Government is compliant with a wide range of certifications and standards, including:\n",
      "   - FedRAMP Moderate and High JAB P-ATO\n",
      "   - DoD DISA SRG Levels 2, 4, and 5\n",
      "   - NIST SP 800-171\n",
      "   - FIPS 140-2\n",
      "   - CJIS (Criminal Justice Information Services)\n",
      "   - ITAR (International Traffic in Arms Regulations)\n",
      "   - IRS 1075\n",
      "\n",
      "2. **Security Features**:\n",
      "   - **Dedicated Physical Network**: Azure Government provides a dedicated physical instance of Microsoft Azure with a dedicated network, offering geo-replication between locations.\n",
      "   - **ExpressRoute**: Dedicated ExpressRoute sites for government are included in Azure Government's DoD and FedRAMP compliance scope, ensuring secure and reliable connectivity.\n",
      "   - **Identity and Access Management**: Azure Active Directory provides consistent identity management across cloud and on-premises environments.\n",
      "   - **Integrated Management and Security**: Azure offers integrated management and security features to ensure consistent data platform and unified development across environments.\n",
      "\n",
      "3. **CJIS Compliance**: Microsoft has committed to CJIS regulations in multiple states, allowing law enforcement agencies to leverage cloud-based solutions for criminal justice applications.\n",
      "\n",
      "These compliance standards and security features make Microsoft Azure Government a suitable platform to meet the stringent security requirements typically associated with government cloud services like JEDI Cloud.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the RFP's stipulations regarding data portability and interoperability, and how can Microsoft Azure's services facilitate these processes?\n",
      ">> Got response: The RFP's stipulations regarding data portability and interoperability are not explicitly detailed in the retrieved documents from the Azure Government file. However, Microsoft Azure's services facilitate data portability and interoperability through various offerings:\n",
      "\n",
      "1. **Data Management and Integration Services**: Azure provides a range of data management services such as Azure Data Explorer for big data analytics, Azure Data Factory for data integration and workflow automation, and Azure Synapse Analytics for cloud data warehousing. These services enable seamless data movement and transformation across different platforms and environments.\n",
      "\n",
      "2. **Hybrid Cloud Architecture**: Azure supports a hybrid cloud architecture that combines cloud and on-premises components. This architecture ensures consistent identity, integrated management, and a consistent data platform, which are crucial for interoperability between different systems.\n",
      "\n",
      "3. **Storage Services**: Azure offers various storage services like Azure Blob Storage for unstructured data, Azure Table Storage for structured data, and Azure Queue Storage for asynchronous messaging. These services provide REST and SDK APIs for accessing and managing data, facilitating data portability across different applications and platforms.\n",
      "\n",
      "4. **Communication and Messaging Services**: Azure Service Bus and Event Hubs support scalable and reliable communication mechanisms, enabling interoperability in service-oriented architectures.\n",
      "\n",
      "5. **Open and Hybrid Solutions**: Azure's commitment to open and hybrid solutions allows for integration with existing on-premises systems and other cloud services, enhancing interoperability.\n",
      "\n",
      "These services collectively support the goals of data portability and interoperability by providing flexible, scalable, and integrated solutions that can work across various environments and platforms.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the expectations for program management and oversight as per the RFP, and how can Microsoft Azure's management tools and practices align with these expectations?\n",
      ">> Got response: To address the expectations for program management and oversight as per the RFP and how Microsoft Azure's management tools and practices align with these expectations, let's break down the information retrieved:\n",
      "\n",
      "### Expectations for Program Management and Oversight (RFP Context)\n",
      "The retrieved documents from the Azure Government file did not provide specific details about the expectations for program management and oversight as per an RFP. However, typically, RFPs for government projects emphasize the need for:\n",
      "- **Compliance with Standards**: Ensuring adherence to relevant compliance and security standards.\n",
      "- **Robust Security Measures**: Implementing strong security protocols to protect sensitive data.\n",
      "- **Efficient Resource Management**: Effective management of resources to ensure project timelines and budgets are met.\n",
      "- **Regular Reporting and Monitoring**: Continuous monitoring and reporting to track progress and address issues promptly.\n",
      "- **Risk Management**: Identifying and mitigating potential risks throughout the project lifecycle.\n",
      "\n",
      "### Microsoft Azure's Management Tools and Practices\n",
      "From the Azure Wiki file, we can see that Microsoft Azure offers several management tools and practices that align with typical RFP expectations:\n",
      "- **Azure Resource Manager**: Allows users to group related services, making it easier to deploy, manage, and monitor resources efficiently.\n",
      "- **Azure Portal**: A web-based interface for managing Azure services, providing capabilities to browse active resources, adjust settings, and view monitoring data.\n",
      "- **Compliance and Security**: Azure complies with numerous global, US government, industry, and regional standards, ensuring robust security and compliance.\n",
      "- **Azure Functions and IoT Services**: These services support event-driven architectures and IoT management, which can be crucial for projects requiring real-time data processing and management.\n",
      "- **Azure Fabric Controller**: Manages scalability and dependability of services, preventing failures and ensuring efficient resource allocation.\n",
      "\n",
      "### Alignment with RFP Expectations\n",
      "Microsoft Azure's management tools and practices align well with typical RFP expectations through:\n",
      "- **Comprehensive Compliance**: Azure's adherence to various compliance standards ensures that projects meet regulatory requirements.\n",
      "- **Efficient Management**: Tools like Azure Resource Manager and Azure Portal facilitate efficient resource management and monitoring.\n",
      "- **Security and Risk Management**: Azure's security measures and compliance with standards like FedRAMP and NIST SP 800-171 help in managing risks effectively.\n",
      "- **Scalability and Flexibility**: Azure's infrastructure supports scalable and flexible deployment models, which are essential for adapting to project needs.\n",
      "\n",
      "In summary, while specific RFP expectations were not detailed in the retrieved documents, Microsoft Azure's comprehensive suite of management tools and compliance with security standards make it well-suited to meet typical program management and oversight requirements in government projects.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: How does the RFP address the need for logical isolation and secure data transfer, and what capabilities does Microsoft Azure provide to ensure these requirements are met?\n",
      ">> Got response: The RFP addresses the need for logical isolation and secure data transfer by leveraging Microsoft Azure Government's capabilities. Azure Government provides a physically isolated instance of Microsoft Azure, ensuring that data sovereignty remains within the U.S. This isolation is crucial for U.S. government entities that require secure and compliant cloud services. Additionally, Azure Government is operated by screened U.S. persons, further enhancing security and compliance.\n",
      "\n",
      "Microsoft Azure provides several capabilities to ensure logical isolation and secure data transfer:\n",
      "\n",
      "1. **Physical and Logical Isolation**: Azure Government offers a physically isolated cloud environment specifically for U.S. government entities, ensuring that data and operations are separate from the commercial Azure cloud.\n",
      "\n",
      "2. **Compliance and Security Standards**: Azure complies with numerous global, U.S. government, industry, and regional certifications and compliance standards, such as FedRAMP, DoD DISA SRG, and CJIS, which are critical for secure data handling and transfer.\n",
      "\n",
      "3. **Identity and Access Management**: Azure Active Directory and related services provide consistent identity management and secure access control across cloud and on-premises environments.\n",
      "\n",
      "4. **Data Protection**: Azure offers services like Azure Information Protection to safeguard sensitive information and ensure secure data transfer.\n",
      "\n",
      "5. **Blockchain and IoT Security**: Azure supports secure infrastructure for blockchain networks and IoT devices, ensuring secure data transfer and management.\n",
      "\n",
      "These capabilities collectively ensure that Microsoft Azure can meet the requirements for logical isolation and secure data transfer as outlined in the RFP.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the RFP's requirements for tactical edge capabilities, and how can Microsoft Azure's solutions support operations in communication-degraded or disconnected environments?\n",
      ">> Got response: ### RFP Requirements for Tactical Edge Capabilities\n",
      "\n",
      "The retrieved documents did not provide specific details about RFP requirements for tactical edge capabilities. However, Microsoft Azure Government is designed to meet various compliance and security standards, which could be relevant for tactical edge operations. Azure Government provides dedicated physical networks, geo-replication, and compliance with standards like FedRAMP and CJIS, which are critical for secure and reliable operations in government and defense sectors.\n",
      "\n",
      "### Microsoft Azure's Solutions for Communication-Degraded or Disconnected Environments\n",
      "\n",
      "Microsoft Azure offers several solutions that can support operations in communication-degraded or disconnected environments:\n",
      "\n",
      "1. **Azure IoT Edge**: This service allows cloud intelligence to be deployed locally on IoT edge devices. It enables the processing of data at the edge, reducing the need for constant cloud connectivity.\n",
      "\n",
      "2. **Azure Orbital**: This service provides connectivity to remote locations without ground infrastructure by using satellite data. It can be particularly useful in areas where traditional communication networks are unavailable or unreliable.\n",
      "\n",
      "3. **Azure Service Bus**: Supports communication between applications running on Azure and off-premises devices, which can help maintain operations even when connectivity is intermittent.\n",
      "\n",
      "4. **Azure Stack HCI**: This infrastructure product allows for the running of virtualized workloads on-premises, which can be connected to Azure for cloud services, providing flexibility in disconnected environments.\n",
      "\n",
      "These solutions enable Azure to support operations in environments where communication may be degraded or disconnected, ensuring continuity and resilience in critical operations.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What does the RFP specify about the integration of third-party services and applications, and how can Microsoft Azure's marketplace and APIs support this integration?\n",
      ">> Got response: The integration of third-party services and applications in Microsoft Azure is supported through various features and services. Azure provides a platform that allows developers to build and deploy applications using multiple programming languages such as ASP.NET, PHP, Node.js, Java, or Python. These applications can be deployed using various methods like FTP, Git, Mercurial, Team Foundation Server, or through the user portal. Azure also offers a gallery of open-source applications that can be deployed, which is part of its platform as a service (PaaS) offerings.\n",
      "\n",
      "Azure's marketplace and APIs further support this integration by providing a wide range of services and tools. Azure offers REST and SDK APIs for storing and accessing data on the cloud, which facilitates the integration of third-party services. The Azure Marketplace is a platform where developers can find, try, and purchase applications and services that run on Azure. It provides a variety of solutions that can be integrated into existing applications, enhancing their functionality and performance.\n",
      "\n",
      "Additionally, Azure provides services like Azure Kubernetes Service (AKS) for deploying production-ready Kubernetes clusters, Azure Functions for serverless computing, and Azure IoT Hub for managing IoT assets. These services enable seamless integration and management of third-party applications and services within the Azure ecosystem.\n",
      "\n",
      "Overall, Microsoft Azure's marketplace and APIs offer robust support for integrating third-party services and applications, providing developers with the tools and resources needed to build, deploy, and manage applications efficiently.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: How does the RFP outline the approach to small business participation, and what strategies can be employed to maximize small business involvement using Microsoft Azure's ecosystem?\n",
      ">> Got response: The retrieved documents did not provide specific details on how the RFP outlines the approach to small business participation. However, I can provide some general strategies that can be employed to maximize small business involvement using Microsoft Azure's ecosystem based on the information available:\n",
      "\n",
      "1. **Utilize Azure's Platform Services**: Small businesses can leverage Azure's Platform as a Service (PaaS) offerings, such as Azure Web Apps and Azure Functions, to build and deploy applications without the need to manage underlying infrastructure. This reduces costs and complexity, allowing small businesses to focus on innovation and growth.\n",
      "\n",
      "2. **Leverage Azure IoT and AI Capabilities**: Small businesses can take advantage of Azure IoT Hub and Azure Machine Learning to develop smart solutions that can enhance their products and services. These tools can help small businesses create innovative solutions in areas like smart devices, predictive maintenance, and data analytics.\n",
      "\n",
      "3. **Participate in Azure's Partner Network**: By joining the Microsoft Partner Network, small businesses can gain access to resources, training, and support to help them build and market their solutions. This network also provides opportunities for collaboration with other businesses and access to a broader customer base.\n",
      "\n",
      "4. **Adopt Azure's Blockchain Services**: Small businesses can use Azure Blockchain Workbench to develop and deploy blockchain applications. This can be particularly useful for businesses looking to enhance transparency, security, and efficiency in their operations.\n",
      "\n",
      "5. **Utilize Azure's Global Reach**: With Azure's extensive global infrastructure, small businesses can expand their reach to new markets and customers. Azure's regional presence allows businesses to deploy applications closer to their customers, improving performance and user experience.\n",
      "\n",
      "6. **Engage in Azure's Training and Certification Programs**: Small businesses can benefit from Azure's training and certification programs to upskill their workforce, ensuring they have the necessary expertise to leverage Azure's capabilities effectively.\n",
      "\n",
      "For a more detailed and specific approach outlined in an RFP, it would be necessary to access the actual RFP document or consult with the issuing organization.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What are the RFP's requirements for compliance with federal regulations and standards, and how does Microsoft Azure ensure adherence to these regulations?\n",
      ">> Got response: The RFP's requirements for compliance with federal regulations and standards, and how Microsoft Azure ensures adherence to these regulations, can be summarized as follows:\n",
      "\n",
      "1. **Compliance with Federal Regulations and Standards**:\n",
      "   - Microsoft Azure Government is specifically designed to meet the stringent compliance requirements of U.S. government entities. It provides a secure and compliant cloud environment that is operated by screened U.S. persons and is physically isolated from other Azure instances.\n",
      "   - Azure Government has achieved compliance with several federal standards, including FedRAMP High, which is a standardized approach to security assessment, authorization, and continuous monitoring for cloud services used by the federal government.\n",
      "   - Azure Government also covers compliance with the Criminal Justice Information Services (CJIS) standards in 26 states, ensuring that law enforcement agencies can securely use cloud services.\n",
      "\n",
      "2. **Ensuring Adherence to Regulations**:\n",
      "   - Microsoft Azure has established the Azure Trust Center, which provides information on compliance programs and certifications, such as ISO 27001:2005 and HIPAA. This center helps organizations understand how Azure meets various compliance requirements.\n",
      "   - Azure Government offers dedicated physical networks and geo-replication between locations to ensure data sovereignty and security.\n",
      "   - Microsoft Azure has received the Joint Authorization Board (JAB) Provisional Authority to Operate (P-ATO) under FedRAMP guidelines, which demonstrates its commitment to maintaining high security and compliance standards.\n",
      "\n",
      "Overall, Microsoft Azure ensures adherence to federal regulations and standards by providing a secure, compliant, and dedicated cloud environment tailored for U.S. government needs, supported by a comprehensive compliance framework and continuous monitoring.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What are the RFP's criteria for evaluating cloud service automation, and how can Microsoft Azure's automation tools and APIs fulfill these criteria?\n",
      ">> Got response: To address the question of RFP criteria for evaluating cloud service automation and how Microsoft Azure's automation tools and APIs fulfill these criteria, let's break it down into two parts:\n",
      "\n",
      "1. **RFP Criteria for Evaluating Cloud Service Automation:**\n",
      "   - The retrieved documents did not explicitly list RFP criteria for evaluating cloud service automation. However, typical criteria might include factors such as scalability, compliance with standards, integration capabilities, ease of use, cost-effectiveness, security features, and support for various deployment models.\n",
      "\n",
      "2. **Microsoft Azure's Automation Tools and APIs:**\n",
      "   - **Azure Automation Tools:** Azure provides a range of automation tools such as Azure Functions, which support serverless computing and allow for event-driven execution without managing server resources. Azure Logic Apps enable workflow automation and integration, supporting hybrid apps and line-of-business integration.\n",
      "   - **APIs and Integration:** Azure offers APIs built on REST, HTTP, and XML, allowing developers to interact with Azure services. It also provides a client-side managed class library for encapsulating functions and integrates with development environments like Microsoft Visual Studio, Git, and Eclipse.\n",
      "   - **Deployment Models:** Azure supports both the classic model and the Azure Resource Manager, which allows grouping related services for easier deployment, management, and monitoring.\n",
      "   - **Platform Services:** Azure's platform as a service (PaaS) offerings include App Services for web and mobile apps, SQL PaaS for scalable databases, and Azure Media Services for media processing.\n",
      "   - **Security and Compliance:** Azure Government provides a dedicated physical network and compliance with standards like FedRAMP and CJIS, which are crucial for government-related cloud services.\n",
      "\n",
      "In summary, while the specific RFP criteria were not detailed in the retrieved documents, Microsoft Azure's automation tools and APIs offer a comprehensive suite of services that can meet various typical criteria for cloud service automation, including scalability, integration, and compliance.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced event CollectedAnswersEvent\n",
      "Running step generate_output\n",
      ">> GENERATING FINAL OUTPUT\n",
      "# Response to JEDI Cloud RFP # HQ0034-18-R-0077\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Microsoft Azure is pleased to submit this proposal in response to the JEDI Cloud RFP # HQ0034-18-R-0077. Our proposal outlines how Microsoft Azure's comprehensive suite of cloud services meets the requirements outlined in the RFP, including high availability, security, data portability, program management, and compliance with federal regulations. We are committed to delivering a secure, scalable, and flexible cloud solution that supports the Department of Defense's mission-critical operations.\n",
      "\n",
      "## Technical Approach\n",
      "\n",
      "### High Availability and Failover\n",
      "\n",
      "The RFP requires high availability and failover capabilities for cloud services. Microsoft Azure offers several solutions to meet these requirements:\n",
      "\n",
      "- **Azure Site Recovery**: Provides comprehensive disaster recovery solutions, supporting site-to-Azure, any cloud, and site-to-site recovery options.\n",
      "- **Azure Kubernetes Service (AKS)**: Enables deployment of production-ready Kubernetes clusters, ensuring high availability and managing failover scenarios.\n",
      "- **Azure Functions**: Supports serverless computing architectures, contributing to high availability by automatically scaling based on demand.\n",
      "- **Azure Fabric Controller**: Maintains scalability and dependability of services, preventing failures and managing web applications, memory allocation, and load balancing.\n",
      "\n",
      "### Security Requirements\n",
      "\n",
      "Microsoft Azure Government provides robust compliance standards and security features to address the JEDI Cloud's security requirements:\n",
      "\n",
      "- **Compliance Standards**: Azure Government complies with FedRAMP Moderate and High JAB P-ATO, DoD DISA SRG Levels 2, 4, and 5, NIST SP 800-171, FIPS 140-2, CJIS, ITAR, and IRS 1075.\n",
      "- **Security Features**: Includes dedicated physical networks, ExpressRoute for secure connectivity, Azure Active Directory for identity management, and integrated management and security features.\n",
      "\n",
      "### Data Portability and Interoperability\n",
      "\n",
      "Microsoft Azure facilitates data portability and interoperability through:\n",
      "\n",
      "- **Data Management Services**: Azure Data Explorer, Azure Data Factory, and Azure Synapse Analytics enable seamless data movement and transformation.\n",
      "- **Hybrid Cloud Architecture**: Supports consistent identity, integrated management, and a consistent data platform across environments.\n",
      "- **Storage Services**: Azure Blob Storage, Azure Table Storage, and Azure Queue Storage provide APIs for accessing and managing data.\n",
      "\n",
      "### Program Management and Oversight\n",
      "\n",
      "Microsoft Azure's management tools align with typical RFP expectations for program management and oversight:\n",
      "\n",
      "- **Azure Resource Manager**: Facilitates efficient resource management and monitoring.\n",
      "- **Azure Portal**: Provides a web-based interface for managing Azure services.\n",
      "- **Compliance and Security**: Adheres to numerous global, US government, industry, and regional standards.\n",
      "\n",
      "### Logical Isolation and Secure Data Transfer\n",
      "\n",
      "Microsoft Azure ensures logical isolation and secure data transfer through:\n",
      "\n",
      "- **Physical and Logical Isolation**: Azure Government offers a physically isolated cloud environment for U.S. government entities.\n",
      "- **Identity and Access Management**: Azure Active Directory provides secure access control.\n",
      "- **Data Protection**: Azure Information Protection safeguards sensitive information.\n",
      "\n",
      "### Tactical Edge Capabilities\n",
      "\n",
      "Microsoft Azure supports operations in communication-degraded or disconnected environments with:\n",
      "\n",
      "- **Azure IoT Edge**: Deploys cloud intelligence locally on IoT edge devices.\n",
      "- **Azure Orbital**: Provides connectivity to remote locations using satellite data.\n",
      "- **Azure Stack HCI**: Allows running virtualized workloads on-premises, connected to Azure for cloud services.\n",
      "\n",
      "### Integration of Third-Party Services\n",
      "\n",
      "Microsoft Azure supports integration of third-party services through:\n",
      "\n",
      "- **Azure Marketplace**: Offers a platform for finding, trying, and purchasing applications and services.\n",
      "- **APIs and Integration**: Provides REST and SDK APIs for storing and accessing data.\n",
      "\n",
      "### Small Business Participation\n",
      "\n",
      "Microsoft Azure encourages small business participation by:\n",
      "\n",
      "- **Utilizing Azure's Platform Services**: Reducing costs and complexity for small businesses.\n",
      "- **Leveraging Azure IoT and AI Capabilities**: Developing smart solutions.\n",
      "- **Participating in Azure's Partner Network**: Gaining access to resources and collaboration opportunities.\n",
      "\n",
      "### Compliance with Federal Regulations\n",
      "\n",
      "Microsoft Azure ensures adherence to federal regulations through:\n",
      "\n",
      "- **Azure Trust Center**: Provides information on compliance programs and certifications.\n",
      "- **FedRAMP Compliance**: Achieved JAB Provisional Authority to Operate under FedRAMP guidelines.\n",
      "\n",
      "### Cloud Service Automation\n",
      "\n",
      "Microsoft Azure's automation tools fulfill cloud service automation criteria with:\n",
      "\n",
      "- **Azure Automation Tools**: Azure Functions and Logic Apps support serverless computing and workflow automation.\n",
      "- **APIs and Integration**: Offers APIs for interacting with Azure services.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Microsoft Azure is committed to providing a secure, scalable, and flexible cloud solution that meets the JEDI Cloud RFP requirements. Our comprehensive suite of services, compliance with federal regulations, and support for small business participation make us the ideal partner for the Department of Defense's cloud needs. We look forward to the opportunity to support the DoD's mission-critical operations with our innovative cloud solutions.Step generate_output produced event StopEvent\n",
      "# Response to JEDI Cloud RFP # HQ0034-18-R-0077\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Microsoft Azure is pleased to submit this proposal in response to the JEDI Cloud RFP # HQ0034-18-R-0077. Our proposal outlines how Microsoft Azure's comprehensive suite of cloud services meets the requirements outlined in the RFP, including high availability, security, data portability, program management, and compliance with federal regulations. We are committed to delivering a secure, scalable, and flexible cloud solution that supports the Department of Defense's mission-critical operations.\n",
      "\n",
      "## Technical Approach\n",
      "\n",
      "### High Availability and Failover\n",
      "\n",
      "The RFP requires high availability and failover capabilities for cloud services. Microsoft Azure offers several solutions to meet these requirements:\n",
      "\n",
      "- **Azure Site Recovery**: Provides comprehensive disaster recovery solutions, supporting site-to-Azure, any cloud, and site-to-site recovery options.\n",
      "- **Azure Kubernetes Service (AKS)**: Enables deployment of production-ready Kubernetes clusters, ensuring high availability and managing failover scenarios.\n",
      "- **Azure Functions**: Supports serverless computing architectures, contributing to high availability by automatically scaling based on demand.\n",
      "- **Azure Fabric Controller**: Maintains scalability and dependability of services, preventing failures and managing web applications, memory allocation, and load balancing.\n",
      "\n",
      "### Security Requirements\n",
      "\n",
      "Microsoft Azure Government provides robust compliance standards and security features to address the JEDI Cloud's security requirements:\n",
      "\n",
      "- **Compliance Standards**: Azure Government complies with FedRAMP Moderate and High JAB P-ATO, DoD DISA SRG Levels 2, 4, and 5, NIST SP 800-171, FIPS 140-2, CJIS, ITAR, and IRS 1075.\n",
      "- **Security Features**: Includes dedicated physical networks, ExpressRoute for secure connectivity, Azure Active Directory for identity management, and integrated management and security features.\n",
      "\n",
      "### Data Portability and Interoperability\n",
      "\n",
      "Microsoft Azure facilitates data portability and interoperability through:\n",
      "\n",
      "- **Data Management Services**: Azure Data Explorer, Azure Data Factory, and Azure Synapse Analytics enable seamless data movement and transformation.\n",
      "- **Hybrid Cloud Architecture**: Supports consistent identity, integrated management, and a consistent data platform across environments.\n",
      "- **Storage Services**: Azure Blob Storage, Azure Table Storage, and Azure Queue Storage provide APIs for accessing and managing data.\n",
      "\n",
      "### Program Management and Oversight\n",
      "\n",
      "Microsoft Azure's management tools align with typical RFP expectations for program management and oversight:\n",
      "\n",
      "- **Azure Resource Manager**: Facilitates efficient resource management and monitoring.\n",
      "- **Azure Portal**: Provides a web-based interface for managing Azure services.\n",
      "- **Compliance and Security**: Adheres to numerous global, US government, industry, and regional standards.\n",
      "\n",
      "### Logical Isolation and Secure Data Transfer\n",
      "\n",
      "Microsoft Azure ensures logical isolation and secure data transfer through:\n",
      "\n",
      "- **Physical and Logical Isolation**: Azure Government offers a physically isolated cloud environment for U.S. government entities.\n",
      "- **Identity and Access Management**: Azure Active Directory provides secure access control.\n",
      "- **Data Protection**: Azure Information Protection safeguards sensitive information.\n",
      "\n",
      "### Tactical Edge Capabilities\n",
      "\n",
      "Microsoft Azure supports operations in communication-degraded or disconnected environments with:\n",
      "\n",
      "- **Azure IoT Edge**: Deploys cloud intelligence locally on IoT edge devices.\n",
      "- **Azure Orbital**: Provides connectivity to remote locations using satellite data.\n",
      "- **Azure Stack HCI**: Allows running virtualized workloads on-premises, connected to Azure for cloud services.\n",
      "\n",
      "### Integration of Third-Party Services\n",
      "\n",
      "Microsoft Azure supports integration of third-party services through:\n",
      "\n",
      "- **Azure Marketplace**: Offers a platform for finding, trying, and purchasing applications and services.\n",
      "- **APIs and Integration**: Provides REST and SDK APIs for storing and accessing data.\n",
      "\n",
      "### Small Business Participation\n",
      "\n",
      "Microsoft Azure encourages small business participation by:\n",
      "\n",
      "- **Utilizing Azure's Platform Services**: Reducing costs and complexity for small businesses.\n",
      "- **Leveraging Azure IoT and AI Capabilities**: Developing smart solutions.\n",
      "- **Participating in Azure's Partner Network**: Gaining access to resources and collaboration opportunities.\n",
      "\n",
      "### Compliance with Federal Regulations\n",
      "\n",
      "Microsoft Azure ensures adherence to federal regulations through:\n",
      "\n",
      "- **Azure Trust Center**: Provides information on compliance programs and certifications.\n",
      "- **FedRAMP Compliance**: Achieved JAB Provisional Authority to Operate under FedRAMP guidelines.\n",
      "\n",
      "### Cloud Service Automation\n",
      "\n",
      "Microsoft Azure's automation tools fulfill cloud service automation criteria with:\n",
      "\n",
      "- **Azure Automation Tools**: Azure Functions and Logic Apps support serverless computing and workflow automation.\n",
      "- **APIs and Integration**: Offers APIs for interacting with Azure services.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Microsoft Azure is committed to providing a secure, scalable, and flexible cloud solution that meets the JEDI Cloud RFP requirements. Our comprehensive suite of services, compliance with federal regulations, and support for small business participation make us the ideal partner for the Department of Defense's cloud needs. We look forward to the opportunity to support the DoD's mission-critical operations with our innovative cloud solutions.\n"
     ]
    }
   ],
   "source": [
    "handler = workflow.run(rfp_template_path=str(Path(data_dir) / \"jedi_cloud_rfp.pdf\"))\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, LogEvent):\n",
    "        if event.delta:\n",
    "            print(event.msg, end=\"\")\n",
    "        else:\n",
    "            print(event.msg)\n",
    "\n",
    "response = await handler\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_parse",
   "language": "python",
   "name": "llama_parse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
